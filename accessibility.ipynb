{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessibility to health facilities\n",
    "\n",
    "This is an exploratory notebook that leverages Partnership data. We are guided by the suggestions and pointers given in our meetings on the subjects with experts across the Bank and external partners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you are running ddp code for the first time, you need to install the library that includes many helper functions to easy access to partner data.\n",
    "\n",
    "You need to be a added to the [Github repository](https://github.com/datapartnership/devdatapartnership) to get access. If you cannot see it, you don't have access to install the library. If so, please contact datapartnership@worldbank.org with your Github username to get added to the repository.\n",
    "\n",
    "```sh\n",
    "conda create -n ddp python=3\n",
    "conda activate ddp\n",
    "/path/to/python -m pip install -e git+ssh://git@github.com/datapartnership/devdatapartnership.git#egg=devdatapartnership\n",
    "```\n",
    "Note: You need to restart the kernel to be able to import after install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys ; sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate using DDP credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "env_path = Path('~/')/'.ddp' / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "load_dotenv(override=True);\n",
    "MAPBOX_ACCESS_TOKEN = os.getenv(\"MAPBOX_ACCESS_TOKEN\")\n",
    "\n",
    "location='Senegal'\n",
    "data_folder=Path('.')/'data'/location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accesibility to health facilities\n",
    "\n",
    "This section explores who to measure accesibility, in minutes, to health facilities. \n",
    "\n",
    "We will assume that a region needs to know how far away (by car) their entire population is from their closest hospital. You can use this to see regions that are too far away, or where to locate additional services that cater those most in need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing engine\n",
    "\n",
    "One of our partners, Mapbox, offers traffic-aware global travel times. We will set up the functions to calculate distance in minutes walking, biking, driving and driving with real-time traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple point to point call\n",
    "\n",
    "import requests  #http framework to make Mapbox API requests for routes\n",
    "import json # handle response as json\n",
    "import datetime # save timestamp\n",
    "\n",
    "osrm_server=\"https://api.mapbox.com/directions-matrix/v1/mapbox/\"\n",
    "modes=['driving-traffic', 'driving', 'cycling', 'walking']\n",
    "mode = modes[1]\n",
    "url=osrm_server+mode+'/'\n",
    "params=\"?annotations=distance,duration&access_token=\"+MAPBOX_ACCESS_TOKEN\n",
    "comma=\"%2C\"\n",
    "sep=\"%3B\"\n",
    "\n",
    "origin=[43.394020,-5.706718]\n",
    "destination=[43.523757,-6.047233]\n",
    "fullurl=url+str(origin[1])+','+str(origin[0])+\";\"+str(destination[1])+','+str(destination[0])+params\n",
    "response = requests.get(fullurl) #do the request\n",
    "response.raise_for_status() # ensure we notice bad responses\n",
    "response=json.loads(response.text)\n",
    "#print(response)\n",
    "print, fullurl\n",
    "print(\"Between La Corrada and Nore√±a there are %2.1f km and ~%2.0f minutes driving.\"%\n",
    "      (response['distances'][0][1]/1000.,\n",
    "       response['durations'][0][1]/60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data we need\n",
    "\n",
    "1. Origins: From where to start to travel time (population centers, zip codes, cities, ...)\n",
    "2. Population on origins: How many people are located at the origin?\n",
    "3. Destinations: The set of destinations. Health facilities in this case\n",
    "\n",
    "In our case, as a proxy for 1. and 2. we will use our partner Facebook and their [population density map](https://data.humdata.org/dataset/highresolutionpopulationdensitymaps). We also have estimates by age bracket at lower resoltion from [worldpop](https://www.worldpop.org/project/categories?id=8). We might use these on a later stage to estimate impact.\n",
    "\n",
    "For 3 we use the hospitals and health centers tagged as such on OSM (using e.g. [overpass-turbo](https://overpass-turbo.eu/s/Rlq))\n",
    "\n",
    "We choose Senegal, as they are one of the developing countries with highest known cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population density\n",
    "\n",
    "Population Density maps are **huge** files where every pixel is ~23m^2. To manage the computation our strategy is to first cluster the country in windows of size e.g. `2000 pixels`. If the window has no population inside, we skip. If it does be split the window in 4 sub-windows, and repeat the process until the window has an arbitraty minimum size e.g. `125 pixels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_density_url=\"https://data.humdata.org/dataset/dbd7b22d-7426-4eb0-b3c4-faa29a87f44b/resource/f84782aa-b726-4370-91cc-9bca318ee067/download/population_sen_2018-10-01.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data\n",
    "import urllib\n",
    "\n",
    "print(\"Getting %s population data\"%(location) )\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "pop_file=data_folder/'pop_density/'\n",
    "if not os.path.exists(pop_file.with_suffix('.zip')):\n",
    "    print(\"Downloading pop density\")\n",
    "    urllib.request.urlretrieve (pop_density_url,pop_file.with_suffix('.zip'))\n",
    "if not os.path.exists(pop_file):\n",
    "    print(\"Unzipping pop density\")\n",
    "    urllib.request.urlretrieve (pop_density_url,pop_file)\n",
    "\n",
    "#TODO get this file\n",
    "map_file=pop_file/'population_sen_2018-10-01.tif'\n",
    "print(\"Map file: %s\"%map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from rasterio.windows import Window\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "def get_pop(map_file,left_x,top_y,window,plot=False):\n",
    "    \"\"\"\n",
    "    get_pop(raster filename,left_x,top_y,window,plot=False)\n",
    "    \n",
    "    Given a raster file, and row,cols ranges,\n",
    "    return the lonlat of the ranges, nancount, and the nunsum\n",
    "    \n",
    "    Optionally plot the raster window [False]\n",
    "    \"\"\"\n",
    "    right_x,bottom_y = left_x + window, top_y + window\n",
    "    with rasterio.open(map_file) as src:\n",
    "        left_lon, top_lat = src.xy(top_y,left_x )\n",
    "        right_lon, bottom_lat = src.xy(bottom_y, right_x )\n",
    "        center_lon , center_lat = (right_lon + left_lon)/2., (top_lat+bottom_lat)/2.\n",
    "                             #Window(col_off, row_off, width, height)\n",
    "        w = src.read(1, window=Window(left_x, top_y, window, window))\n",
    "        if plot:\n",
    "            pyplot.imshow(w, cmap='pink')\n",
    "            pyplot.show()\n",
    "        nancount=np.count_nonzero(~np.isnan(w))\n",
    "        count = np.size(w)\n",
    "        tot_pop=np.nansum(w)\n",
    "    if count == 0:\n",
    "        return {} #Out of bounds\n",
    "    if tot_pop == 0 or window < 1: #Mark the window to furhter split.\n",
    "        split=False\n",
    "    else:\n",
    "        split=True\n",
    "    out={'window':window,\n",
    "         'left_x':left_x,\n",
    "         'right_x':right_x,\n",
    "         'top_y':top_y,\n",
    "         'bottom_y':bottom_y,\n",
    "         'left_lon':left_lon, \n",
    "         'top_lat':top_lat, \n",
    "         'right_lon':right_lon,\n",
    "         'bottom_lat':bottom_lat,\n",
    "         'center_lon':center_lon , \n",
    "         'center_lat':center_lat,\n",
    "         'count': count,\n",
    "         'nancount':nancount,\n",
    "         'tot_pop':tot_pop,\n",
    "         'split': split}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan the raster map with big windows\n",
    "origins=pd.DataFrame()\n",
    "window=2000\n",
    "with rasterio.open(map_file) as src:\n",
    "    for left_x in np.arange(0,src.width,window):\n",
    "        for top_y in np.arange(0,src.height,window):\n",
    "            out=get_pop(map_file,left_x,top_y,window,plot=False)\n",
    "            if out != {}:\n",
    "                origins=origins.append([out])\n",
    "        print(\"%i/%i\\r\"%(left_x,src.width),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(map_file,origin,plot=False):\n",
    "    \"\"\"\n",
    "    Split a window row in 4 parts, and return new rows results\n",
    "    \"\"\"\n",
    "    origins=pd.DataFrame()\n",
    "    \n",
    "    window=int(origin.window/2)\n",
    "    for left_x in np.arange(origin.left_x,origin.right_x,window):\n",
    "        for top_y in np.arange(origin.top_y,origin.bottom_y,window):\n",
    "            out=get_pop(map_file,left_x,top_y,window,plot=plot)\n",
    "            if out != {}:\n",
    "                origins=origins.append([out])\n",
    "    return origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a splitting pass\n",
    "#run this cell as many times as you want to split the windows\n",
    "print(\"%i regions need splitting\"%len(origins[origins['split']==True]))\n",
    "olen=len(origins)\n",
    "for i in np.arange(olen):\n",
    "    print(\"%i/%i\\r\"%(i+1,olen),end=\"\")\n",
    "    if origins.iloc[i,origins.columns.get_loc('split')] == True:\n",
    "        origins.iloc[i,origins.columns.get_loc('split')]='done'\n",
    "        s=split(map_file,origins.iloc[i])\n",
    "        origins=origins.append(s,sort=False)\n",
    "print(\"done.\")\n",
    "print(\"We now have %i regions, %i will be split in next round\"%(len(origins),len(origins[origins['split']==True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins=origins[origins['tot_pop']>0]\n",
    "origins=origins[origins['split']!='done']\n",
    "print(\"We have %i regions of size %i, %i with population >0\"%\n",
    "      (len(origins),min(origins['window']),len(origins[origins['tot_pop']>0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it geopandas using the center latlon as location\n",
    "import geopandas as gdp\n",
    "from shapely.geometry import Point\n",
    "origins=gdp.GeoDataFrame(origins,crs='epsg:4327', geometry=[Point(xy) for xy in zip(origins['center_lon'], origins['center_lat'])])\n",
    "origins.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(origins['window'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hospital destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals_file=data_folder/'hospitals.geojson'\n",
    "print(\"Destination file: %s\"%hospitals_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "\n",
    "hospitals = gpd.read_file(hospitals_file).to_crs('epsg:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals['lat']=hospitals.to_crs(\"epsg:4327\").geometry.y\n",
    "hospitals['lon']=hospitals.to_crs(\"epsg:4327\").geometry.x\n",
    "\n",
    "ax = hospitals.plot(figsize=(10, 10), alpha=0.8,color='red')\n",
    "ctx.add_basemap(ax)\n",
    "ax.set_axis_off()\n",
    "print(\"There are %i hospital destinations\"%len(hospitals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather travel times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest_geodetic(destinations,origins,n_keep,verbose=False):\n",
    "    \"\"\"\n",
    "    Given a list of origins and destinations, return the \"keep\" number\n",
    "    of destinations that are closest geodetically to each origin.\n",
    "    \n",
    "    Input: destinations,origins <Geopandas>\n",
    "    Output: destinations filtered <Geopandas>\n",
    "    \"\"\"\n",
    "    destinations=destinations.to_crs(origins.crs)\n",
    "    filtered=gdp.GeoDataFrame()\n",
    "    if verbose:\n",
    "        i=0\n",
    "        l=len(origins.index)\n",
    "    for index in origins.index:\n",
    "        if verbose:\n",
    "            i=i+1\n",
    "            print(\"Doing %i of %i\\r\"%(i,l),end=\"\")\n",
    "        distances=destinations.distance(origins.loc[index].geometry)\n",
    "        if len(distances) < n_keep:\n",
    "            n_keep = len(distances)\n",
    "        #query indices\n",
    "        indices=np.argsort(distances.values)[:n_keep]\n",
    "        values=np.sort(distances.values)[:n_keep]\n",
    "        #destination indices\n",
    "        d_indices=distances.index[indices]\n",
    "        filtered = filtered.append(destinations.iloc[indices])\n",
    "    if verbose:\n",
    "        print('done')\n",
    "    return filtered.append(filtered).drop_duplicates(inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_o = origins.sample(frac=1).reset_index(drop=True).head(10)\n",
    "test_d = hospitals.sample(frac=1).reset_index(drop=True).head(10)\n",
    "filtered = n_closest_geodetic(test_d,test_o,2,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "ax = test_d.to_crs('epsg:3857').plot(figsize=(10, 10), alpha=0.8,color='red')\n",
    "filtered.to_crs('epsg:3857').plot(figsize=(10, 10), alpha=0.8,color='yellow',marker='+',ax=ax)\n",
    "test_o.to_crs('epsg:3857').plot(figsize=(10, 10), alpha=0.8,color='blue',marker='*',ax=ax)\n",
    "ctx.add_basemap(ax,zoom=7)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index to be incerasing integers\n",
    "\n",
    "h=hospitals.reset_index(drop=True)\n",
    "o=origins.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#SAVE\n",
    "with open('h-o52k.pickle', 'wb') as handle:\n",
    "    pickle.dump([h,o], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('h-o52k.pickle', 'rb') as handle:\n",
    "    h,o = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import geopandas as gdp\n",
    "def mapbox_matrix_API(origins, destinations, mode=1, name='poi',n_keep=5,do_all=False,verbose=True):\n",
    "    \"\"\"\n",
    "    Given a geopandas set of origins and destinations, return the origins with extra columns\n",
    "    with the closest destination in minutes given the mode of transportation for each origin.\n",
    "    \n",
    "    Also returns the snap distance to the origin (geodetic distance from origin point to closest road)\n",
    "    Keywords:\n",
    "    do_all [False]: By default avoid repeating work that has been done.\n",
    "    \n",
    "    \"\"\"\n",
    "    osrm_server=\"https://api.mapbox.com/directions-matrix/v1/mapbox/\"\n",
    "    modes=['driving-traffic', 'driving', 'cycling', 'walking']\n",
    "    url=osrm_server+modes[mode]+'/'\n",
    "    params=\"?annotations=distance,duration&access_token=\"+MAPBOX_ACCESS_TOKEN\n",
    "\n",
    "\n",
    "    o_type=name\n",
    "    buffer=10/60.  #10 minutes, in hours\n",
    "    overalpenalty=1.05  #5%\n",
    "    batch=int(25/n_keep)\n",
    "    \n",
    "\n",
    "    if n_keep*batch>25:\n",
    "        print(\"limit 25< %i (keep) * %i (batch)\"%(n_keep,batch))\n",
    "\n",
    "    cols=['t_'+o_type,'m_'+o_type,'so_'+o_type]\n",
    "    \n",
    "    #only do empty ones\n",
    "    if not do_all:\n",
    "        queued_origins=origins[origins['t_hospital']==-1]\n",
    "    else:\n",
    "        queued_origins=origins\n",
    "    if verbose:\n",
    "        print(\"Doing %i\"%len(queued_origins))\n",
    "    try:\n",
    "        for i in np.arange(queued_origins.shape[0]/batch):\n",
    "            print(\"Doing batch %i, from %i to %i, of %i\"\n",
    "              %(i+1,batch*i,batch*(i+1),queued_origins.shape[0]),end=\"\\r\")\n",
    "            #get origin batch\n",
    "            o_batch=queued_origins.iloc[int(batch*i):].head(n=batch)\n",
    "\n",
    "\n",
    "            #to reduce API calls calculate keep only n closest (geodetically) to\n",
    "            #each origin.\n",
    "            h_batch=n_closest_geodetic(destinations,o_batch,n_keep)\n",
    "            h_batch_loc=\";\".join([str(i[1])+','+str(i[0]) for i in h_batch[['lat','lon']].values])\n",
    "\n",
    "            #create url params of origin batch\n",
    "            d=\";\".join([str(i[1])+','+str(i[0]) for i in o_batch[['center_lat','center_lon']].values])\n",
    "            d_name=o_batch.index\n",
    "\n",
    "            trail=\".json?destinations=\"+\\\n",
    "            ';'.join([str(x) for x in np.arange(len(h_batch))])+\\\n",
    "            \"&sources=\"+\\\n",
    "            ';'.join([str(x) for x in np.arange(len(h_batch),len(h_batch)+len(o_batch))])\n",
    "\n",
    "            fullurl= url+h_batch_loc+\";\"+d+trail+params\n",
    "\n",
    "            #print(fullurl)\n",
    "            response = requests.get(fullurl)\n",
    "            response.raise_for_status()\n",
    "            response=json.loads(response.text)\n",
    "            #print(response)\n",
    "            response_matrix=response['durations']\n",
    "            durations=[]\n",
    "            h_min=[]\n",
    "            for origin in np.arange(np.shape(response_matrix)[0]):\n",
    "                durations+=[min(response_matrix[origin])]\n",
    "                h_min+=[np.argmin(response_matrix[origin])]\n",
    "            for i in np.arange(len(durations)):\n",
    "                queued_origins.loc[[d_name[i]], ['t_'+o_type]]=buffer+durations[i]/60./60.*overalpenalty\n",
    "                queued_origins.loc[[d_name[i]], ['m_'+o_type]]=h_min[i]\n",
    "                queued_origins.loc[[d_name[i]], ['so_'+o_type]]=response['sources'][i]['distance']\n",
    "    except Exception as err:\n",
    "        print(\"Error. Work done has been saved and returned. \\nError:\",err)\n",
    "    print(\"\\n\")\n",
    "    #update the \"origins\" with the results\n",
    "    \n",
    "    pd.set_option('mode.chained_assignment', None) #'warn'\n",
    "    origins.loc[queued_origins.index, (cols)] = queued_origins.loc[:,(cols)].copy()\n",
    "    print(\"returning\")\n",
    "    \n",
    "    return origins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize columns\n",
    "o_type = 'hospital'\n",
    "cols=['t_'+o_type,'m_'+o_type,'so_'+o_type]\n",
    "for col in cols:\n",
    "    o[col]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(o[o['t_hospital']==-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = mapbox_matrix_API(o, h, name='hospital',n_keep=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.to_file(\"origins\", driver='Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.to_file(\"h.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "o['t_'+o_type].plot.hist(alpha=0.5,bins=100,cumulative=False,density=True,log=True,weights=o['tot_pop'])\n",
    "plt.ylabel('Population %')\n",
    "plt.xlabel('Distance to closest: '+o_type+' [h]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "o['t_'+o_type].plot.hist(alpha=0.5,bins=100,cumulative=False,density=True,log=True)\n",
    "plt.axvline(5,color=\"red\")\n",
    "plt.ylabel('Population %')\n",
    "plt.xlabel('Distance to closest: '+o_type+' [h]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=5\n",
    "\n",
    "o_above = o[o['t_'+o_type]>threshold]\n",
    "print(\"%i people (%.2f%%) live beyond %i hours driving from a hospital\"%\\\n",
    "     (o_above['tot_pop'].sum(),o_above['tot_pop'].sum()/o['tot_pop'].sum()*100,threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "ax = o_above.to_crs('epsg:3857').plot(figsize=(10, 10), alpha=0.8,color='red')\n",
    "h.to_crs('epsg:3857').plot(figsize=(10, 10), alpha=0.8,color='blue',ax=ax)\n",
    "ctx.add_basemap(ax,zoom=7)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import contextily as ctx\n",
    "\n",
    "def biplot(threshold):\n",
    "    o_above = o[o['t_'+o_type]>threshold]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 6)) \n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1]) \n",
    "\n",
    "    ax1=plt.subplot(gs[0])\n",
    "\n",
    "    o_above.to_crs('epsg:3857').plot( alpha=0.8,color='red',ax=ax1)\n",
    "    h.to_crs('epsg:3857').plot( alpha=0.8,color='blue',ax=ax1)\n",
    "    \n",
    "    ctx.add_basemap(ax1,zoom=7)\n",
    "    ax1.set_title(\"(Red) population beyond %i h from hospital (Blue)\"%threshold)\n",
    "    ax1.set_axis_off()\n",
    "    \n",
    "    ax2=plt.subplot(gs[1])\n",
    "    o['t_'+o_type].plot.hist(alpha=0.5,bins=100,cumulative=False,density=True,log=True,ax=ax2)\n",
    "    ax2.axvline(5,color=\"red\")\n",
    "    ax2.set_ylabel('Population %')\n",
    "    ax2.set_xlabel('Distance to closest: '+o_type+' [h]')\n",
    "    ax2.set_title(\"%i people (%.2f%%) beyond %i h driving closest hospital\"%\\\n",
    "     (o_above['tot_pop'].sum(),o_above['tot_pop'].sum()/o['tot_pop'].sum()*100,threshold))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Senegal-threshold-%i.pdf'%threshold)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biplot(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
